In contrast with conventional locking primitives that ensure mutual 
exclusion among concurrent threads regardless of whether they be readers or updaters,
or with reader-writer locks that allow concurrent reads but not in the presence of updates, 
RCU supports concurrency between a single updater and multiple readers


1. RCU is better than rw lock  since there is no contension. 

2. thread access the heap  for locking, processes access shared memory. 


1 . for un-intialized page, 
insert -> vacumme-> build index for perf testing . 
buffer cache missing 

throttling between engine & csd 
1. limit the queue size, and start waiting if engine used all the pages inside shared msg queue.

vacumme is doing adding pages to freelist, and gr extend is done in front ground by process doing insert. 
